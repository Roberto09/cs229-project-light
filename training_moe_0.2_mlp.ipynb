{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40941f2-afb0-48b1-8173-50673ebff6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa01d0f1-64d3-4eed-8a41-880a216b3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a65062-72ba-40f0-ad0c-e37ed36df9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/andriv/.conda/envs/pytorch_cuda-11.8/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset_preprocessing import TokenInfo\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376ae97-4ec1-46d5-b640-566545c2e21d",
   "metadata": {},
   "source": [
    "## Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7943d9f-9fa3-4ae3-8e5b-2b8978c909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importances():\n",
    "    # print(\"this is wrong\")\n",
    "    dir = \"./new_importances_data\"\n",
    "    imp_files = os.listdir(dir)\n",
    "    imp_files = [file for file in imp_files if file.endswith(\".pkl\")]\n",
    "    importances = {}\n",
    "    for imp_file in tqdm(imp_files):\n",
    "        importances.update(pd.read_pickle(f\"{dir}/{imp_file}\"))\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6aee5d8-b934-4388-a280-226e823cfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_imporances(importances):\n",
    "    avg_imps = [torch.zeros_like(imp) for imp in list(importances.values())[0]]\n",
    "    for token, imps in tqdm(importances.items()):\n",
    "        for i, layer_imps in enumerate(imps):\n",
    "            avg_imps[i] += layer_imps / len(importances)\n",
    "    # TODO think harder about averaging method\n",
    "    return avg_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7daa4f-5525-4bc6-ab49-df4e159f3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importances = pd.read_pickle(\"./avg_importances.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f94d76e-fa17-4f7d-b1f6-cdad75876469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4532c3-06f6-4353-b261-92acee331bbc",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b0cc63-e94b-4d1e-aff7-ea5c7310e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84556f1-3c37-4283-bbdb-7d57b2f8d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "434047b0-2814-4a7d-8b36-26bb8cea6ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50295"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b379b1d8-0ab9-44df-83ed-089795112f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=model_revision,\n",
    "    trust_remote_code=True,\n",
    "    # be careful with this?\n",
    "    # torch_dtype=torch.float16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c698778-7f3b-4cf8-8bfe-6b0c54849ca2",
   "metadata": {},
   "source": [
    "## Prune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9250468a-c3e1-498a-8799-bbbbc763f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prunners import prune_mlps_individually\n",
    "from importances import get_mlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e11be390-99df-4b99-9e18-25255d3d269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps = get_mlps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "207a1fcd-edaf-43e2-a52d-ba4fc39b7c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlps), len(avg_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0810f24f-cb59-4c40-9b66-588c669bb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importances = dict(zip(mlps, avg_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c222ae1-5dcd-4801-96dc-0ebdfd10666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_mlps_individually(avg_importances, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b96da5cc-9b2c-44e1-8b38-ef0592767ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=6554, bias=True)\n",
       "          (fc2): Linear(in_features=6554, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028756c1-b952-49e2-acad-476c47285710",
   "metadata": {},
   "source": [
    "## Replace model modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "129af7bc-6a05-4d98-b0e5-ebe9ea37159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experts import Experts, mark_adapters_and_routers_as_trainable, prepare_as_if_peft_model, prepare_model_for_gradient_checkpointing\n",
    "from importances import get_mlps\n",
    "from post_training import get_lora_config, get_training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1694358-33a6-4323-be62-fb5c6660b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = get_lora_config()\n",
    "training_arguments = get_training_arguments(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b3db38f-f332-4fb9-8cbe-da4578d71d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = prepare_as_if_peft_model(model, training_arguments, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c3be121-252c-4076-85f4-1149821f4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(model):\n",
    "    return model.get_submodule(\"model\").get_submodule(\"layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b0ee042-d97a-4807-b94a-5cd147409c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_experts(model):\n",
    "    layers = get_layers(model)\n",
    "    for i, layer in enumerate(layers):\n",
    "        layer.mlp = Experts(\n",
    "            model,\n",
    "            layer.mlp,\n",
    "            lora_config,\n",
    "            i,\n",
    "            layer.mlp.config,\n",
    "            K=2,\n",
    "            output_name='moe_20_mlp',\n",
    "            store_outputs=True # store outputs in eval, need to revert for test\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "691d8884-5815-4a98-a9bf-d278be72d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_experts(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2371bb5-6bd5-4832-94de-07e58a7997f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#layers = get_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82509117-64fd-410c-86bc-6a9145151c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_adapters_and_routers_as_trainable(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44f81670-8720-40f8-871e-88c97cd630e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Experts(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (router): TopKPerceptronRouter(\n",
       "            (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       "          )\n",
       "          (experts_fc1): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=6554, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=6554, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "          (experts_fc2): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=6554, out_features=2048, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=6554, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_model_for_gradient_checkpointing(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8482f4a-8430-4d3e-aa9d-8f7b0def7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"hi this is an example\", \"hi this is an example\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3067f38a-ffb5-471c-8ff5-7f1770837f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = torch.tensor(tokenizer.encode(examples)).view(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84c33521-8b1a-41cc-8ebc-30189ce05c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Experts(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (router): TopKPerceptronRouter(\n",
       "            (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       "          )\n",
       "          (experts_fc1): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=6554, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=6554, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "          (experts_fc2): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=6554, out_features=2048, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=6554, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb57e0-ca3f-49ed-b43b-a5874dc6d583",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5fa8dd8-6987-4888-8583-592da2e56506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_training import get_lora_config, get_training_arguments\n",
    "from dataset import get_baseline_dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "import transformers\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "318fb266-d940-4daa-b643-07247fbc9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pickle\n"
     ]
    }
   ],
   "source": [
    "dataset = get_baseline_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "949f2b82-94fc-4ec3-8728-f2f5ae375a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 60\n",
    "# micro_batch_size = 6\n",
    "# gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "# training_arguments = transformers.TrainingArguments(\n",
    "#     per_device_train_batch_size=micro_batch_size,\n",
    "#     gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "#     warmup_steps=100,\n",
    "#     num_train_epochs=2,\n",
    "#     learning_rate=1e-4,\n",
    "#     fp16=True,\n",
    "#     logging_steps=10,\n",
    "#     logging_first_step=True,\n",
    "#     # optim=torch.optim,\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\",\n",
    "#     eval_steps=100,\n",
    "#     save_steps=200,\n",
    "#     output_dir=\"./tmp\",\n",
    "#     save_total_limit=20,\n",
    "#     load_best_model_at_end=True,\n",
    "#     ddp_find_unused_parameters=None,\n",
    "#     group_by_length=False,\n",
    "#     # metric_for_best_model=\"{}_loss\".format(args.data_path),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "355927ec-3ea2-4b64-9022-d8a5bbed156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0c194ec-6d6b-471a-8c50-706559967b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments.save_strategy=\"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ef8bc33-998c-4c3c-a979-e05d0d6938dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 50000/50000 [00:22<00:00, 2249.34 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 2225.12 examples/s]\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Setup model for training\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Setup tokenizer for trainign\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_data, eval_data = dataset[\"train\"], dataset[\"test\"]\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    # peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024, # tweak this\n",
    "    # TODO: think harder about the datacollator\n",
    "    # data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "    #     tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d199646e-bc7b-49af-b56c-46361f789ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Trainable parameters:\")\\nfor name, param in model.named_parameters():\\n    if param.requires_grad:\\n        print(f\"{name}: {param.numel()} parameters\")'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(\"Trainable parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.numel()} parameters\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f25bee-d634-4262-b712-27b4d6384d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 04:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandriv\u001b[0m (\u001b[33mandriai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/research/andriv/cs229/cs229-project/wandb/run-20240307_145320-kurrg7pn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/andriai/huggingface/runs/kurrg7pn' target=\"_blank\">fanciful-serenity-16</a></strong> to <a href='https://wandb.ai/andriai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/andriai/huggingface' target=\"_blank\">https://wandb.ai/andriai/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/andriai/huggingface/runs/kurrg7pn' target=\"_blank\">https://wandb.ai/andriai/huggingface/runs/kurrg7pn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.497535228729248,\n",
       " 'eval_runtime': 294.8665,\n",
       " 'eval_samples_per_second': 6.783,\n",
       " 'eval_steps_per_second': 0.848}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c6425d9-7eab-4e23-9a44-50e6c2b8a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_expert_stats(model):\n",
    "    layers = get_layers(model)\n",
    "    for i, layer in enumerate(layers):    \n",
    "        experts = layer.mlp\n",
    "        print(f'layer:{i}, initial_distribution of embeddings to experts:\\n {experts.expand_expert_stats()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "908fd37d-91f4-4fd5-b74c-43b0d8f80bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:0, initial_distribution of embeddings to experts:\n",
      " {0: (376471, 0.3165251300274457, 0.32638070104866007), 1: (14467, 0.19200466924574935, 0.012542133662542306), 2: (382543, 0.5960781258468969, 0.3316448080230816), 3: (24089, 0.2440519366536918, 0.020883905287687955), 4: (31445, 0.2530766414636875, 0.027261173223103813), 5: (23027, 0.20391130103639182, 0.01996320673583754), 6: (720210, 0.22261037494570812, 0.6243844670698552), 7: (734692, 0.1955460749252302, 0.6369396049492315)}\n",
      "\n",
      "layer:1, initial_distribution of embeddings to experts:\n",
      " {0: (934085, 0.1956401278465879, 0.809802925428619), 1: (32457, 0.24338382158033486, 0.02813852438550741), 2: (82140, 0.2318312082611095, 0.07121109138323253), 3: (32285, 0.6012468226871306, 0.027989409365810354), 4: (42425, 0.25234384911019575, 0.03678025994562503), 5: (1040899, 0.6934197072749734, 0.9024050865560672), 6: (21955, 0.4099594221547316, 0.019033838706097764), 7: (120698, 0.4332449520376379, 0.10463886422904067)}\n",
      "\n",
      "layer:2, initial_distribution of embeddings to experts:\n",
      " {0: (423125, 0.07233290372366746, 0.36682728319369695), 1: (51081, 0.4529681108012876, 0.04428456000665816), 2: (43302, 0.5753347080941293, 0.03754057315652222), 3: (644834, 0.17597237535220872, 0.5590374105309882), 4: (29217, 0.21895114565285692, 0.025329613549353605), 5: (1080676, 0.4530316218746198, 0.9368896687565889), 6: (22727, 0.3776807271836799, 0.019703122399156635), 7: (11982, 0.29702186508860035, 0.010387768407035454)}\n",
      "\n",
      "layer:3, initial_distribution of embeddings to experts:\n",
      " {0: (770623, 0.1780818799649485, 0.6680899059535038), 1: (195079, 0.24846233218542127, 0.169123307717916), 2: (48536, 0.6371784396052059, 0.04207817788381513), 3: (713289, 0.21496559422950662, 0.6183843214226267), 4: (335064, 0.7290193514795108, 0.2904829939521722), 5: (14627, 0.345017907338629, 0.012680845308772124), 6: (55433, 0.48248470339015437, 0.048057516784109196), 7: (174293, 0.43762201887877306, 0.15110293097708483)}\n",
      "\n",
      "layer:4, initial_distribution of embeddings to experts:\n",
      " {0: (283023, 0.6543875524470646, 0.24536616406813516), 1: (108228, 0.25411272238402094, 0.09382802530100427), 2: (274624, 0.22751390650838896, 0.23808466958885868), 3: (201940, 0.34263568550239104, 0.17507143649780835), 4: (724462, 0.1898753218862217, 0.6280707290684125), 5: (526630, 0.16489405037228913, 0.4565607140875548), 6: (39305, 0.44456568170694766, 0.0340753828441436), 7: (148732, 0.6057698437279058, 0.12894287854408257)}\n",
      "\n",
      "layer:5, initial_distribution of embeddings to experts:\n",
      " {0: (252133, 0.647754814903617, 0.21858614686789102), 1: (127964, 0.1846576588393294, 0.11093810686345225), 2: (561755, 0.19180221900631303, 0.4870122551739444), 3: (100409, 0.42258319967381375, 0.08704936053931088), 4: (78682, 0.5053592755311459, 0.0682131859290906), 5: (714596, 0.23028076273771655, 0.6195174221827665), 6: (261527, 0.31124686313085614, 0.2267302543971592), 7: (209878, 0.44273256973602343, 0.18195326804638517)}\n",
      "\n",
      "layer:6, initial_distribution of embeddings to experts:\n",
      " {0: (247854, 0.6430897570841859, 0.21487647727903234), 1: (118756, 0.2881099468186744, 0.10295525162292626), 2: (664888, 0.23457579272736387, 0.5764231814903179), 3: (202373, 0.3989609175273202, 0.1754468248904178), 4: (745682, 0.23741958807527402, 0.6464673611496421), 5: (93664, 0.4338727019368319, 0.08120179770293513), 6: (149572, 0.20077711893856523, 0.1296711146867891), 7: (84155, 0.557422608611319, 0.0729579911779393)}\n",
      "\n",
      "layer:7, initial_distribution of embeddings to experts:\n",
      " {0: (142728, 0.4723794441454066, 0.12373772401930866), 1: (126202, 0.26240654194672974, 0.10941054485934638), 2: (711529, 0.27431196963177124, 0.6168584933140987), 3: (59989, 0.2479556289122418, 0.05200733091050325), 4: (738366, 0.22425326391789902, 0.6401247711257837), 5: (235829, 0.565186887969271, 0.20445143011707262), 6: (200319, 0.3737044808656536, 0.17366611413194252), 7: (91982, 0.46061910679578255, 0.07974359152194418)}\n",
      "\n",
      "layer:8, initial_distribution of embeddings to experts:\n",
      " {0: (229342, 0.6047081045348409, 0.19882753981024248), 1: (125386, 0.5674517024290318, 0.10870311546357432), 2: (112311, 0.2321385242233129, 0.09736777312323143), 3: (765116, 0.24326956659333102, 0.6633156244798313), 4: (168411, 0.23945957833268067, 0.14600354408256117), 5: (91442, 0.584543296231761, 0.07927543971591855), 6: (195344, 0.3808557941126816, 0.16935304888198413), 7: (619592, 0.1650371781654449, 0.5371539144426566)}\n",
      "\n",
      "layer:9, initial_distribution of embeddings to experts:\n",
      " {0: (52608, 0.4558714475310487, 0.04560838928036398), 1: (122257, 0.4174459349702788, 0.10599043583199245), 2: (93743, 0.2981252935759974, 0.08127028657826112), 3: (771543, 0.23193212472595057, 0.6688874979193253), 4: (737941, 0.2489714113837053, 0.6397563183154857), 5: (190763, 0.4195122868613938, 0.16538156106086668), 6: (228537, 0.5992355873139522, 0.1981296468401487), 7: (109552, 0.5044609815060738, 0.09497586417355601)}\n",
      "\n",
      "layer:10, initial_distribution of embeddings to experts:\n",
      " {0: (38491, 0.20590190253124951, 0.0333696873439494), 1: (109980, 0.28786726938331963, 0.09534691782722077), 2: (122084, 0.4053580223633247, 0.10584045386450647), 3: (422641, 0.2086560159437846, 0.36640768046385175), 4: (193754, 0.449271661800615, 0.16797460189757532), 5: (597946, 0.21347889189815483, 0.5183879626033402), 6: (224854, 0.6167351069055894, 0.19493667813349608), 7: (597194, 0.23594614610971676, 0.51773601786606)}\n",
      "\n",
      "layer:11, initial_distribution of embeddings to experts:\n",
      " {0: (221348, 0.6078428397032247, 0.19189715918548522), 1: (425574, 0.18699228493382228, 0.3689504383288021), 2: (82351, 0.2705453701357209, 0.0713940173666981), 3: (441243, 0.2717980092274721, 0.3825346432336459), 4: (751707, 0.21933051127586736, 0.6516907215779837), 5: (208227, 0.38743513665204804, 0.18052193724685126), 6: (77573, 0.4013569599628761, 0.06725174083116019), 7: (98921, 0.585938222517645, 0.08575934222937358)}\n",
      "\n",
      "layer:12, initial_distribution of embeddings to experts:\n",
      " {0: (225674, 0.5837242298678454, 0.1956475753204239), 1: (109065, 0.3755544077758203, 0.09455366060034401), 2: (96384, 0.33374348718668057, 0.08355989568884203), 3: (213413, 0.31887327093141266, 0.1850179284802752), 4: (616927, 0.19248238513441351, 0.5348434985851412), 5: (744919, 0.20833086349977012, 0.6458058799866837), 6: (177432, 0.43627292898446335, 0.15382428008655608), 7: (123130, 0.4699478091789301, 0.1067472812517339)}\n",
      "\n",
      "layer:13, initial_distribution of embeddings to experts:\n",
      " {0: (196400, 0.5013035734025135, 0.17026854574710093), 1: (100735, 0.3795348473350694, 0.08733198551850413), 2: (325908, 0.23409519643690632, 0.2825452199966709), 3: (750931, 0.21605428450375194, 0.651017970093769), 4: (385734, 0.22009879858516415, 0.3344112384175775), 5: (138337, 0.4122748425712158, 0.11993095627808911), 6: (198147, 0.4675753738406477, 0.17178310353437273), 7: (210752, 0.33009720753653204, 0.18271098041391556)}\n",
      "\n",
      "layer:14, initial_distribution of embeddings to experts:\n",
      " {0: (218709, 0.5349401073681596, 0.18960928397048216), 1: (768381, 0.2656209360256644, 0.6661462090107085), 2: (178822, 0.411453786245992, 0.1550293375131776), 3: (147603, 0.35256799230081093, 0.1279640944903734), 4: (683776, 0.2165835501325573, 0.5927980913277479), 5: (67738, 0.5561575152558694, 0.05872530932697109), 6: (79011, 0.36585486865970324, 0.06849841175165067), 7: (162904, 0.4683491402382362, 0.14122926260888866)}\n",
      "\n",
      "layer:15, initial_distribution of embeddings to experts:\n",
      " {0: (207209, 0.5896926247392241, 0.17963938439771404), 1: (766101, 0.305104005601306, 0.6641695680519336), 2: (160703, 0.3591557165061974, 0.13932111052543972), 3: (106478, 0.566360883958715, 0.09231086667036564), 4: (72647, 0.5313805248498837, 0.06298115602285968), 5: (747742, 0.23808967920529434, 0.6482532735948511), 6: (172231, 0.4025730726841841, 0.14931528463629806), 7: (73833, 0.45411818055880643, 0.0640093561005382)}\n",
      "\n",
      "layer:16, initial_distribution of embeddings to experts:\n",
      " {0: (751949, 0.23799535450917525, 0.6519005229429062), 1: (158677, 0.43935042108503425, 0.13756467430505465), 2: (761426, 0.24514059268918462, 0.6601165871386562), 3: (86967, 0.4856187244240574, 0.07539584836042834), 4: (91392, 0.5648346917719403, 0.07923209232647173), 5: (203407, 0.5753388986900397, 0.176343248904178), 6: (75772, 0.5003237273218212, 0.0656903678632858), 7: (177354, 0.427104686122464, 0.15375665815901904)}\n",
      "\n",
      "layer:17, initial_distribution of embeddings to experts:\n",
      " {0: (130634, 0.3223123339434838, 0.11325285745991233), 1: (745491, 0.21148640122094697, 0.6463017741219553), 2: (94360, 0.5750134062671017, 0.08180519336403484), 3: (102266, 0.5623597643487446, 0.0886592825833657), 4: (187359, 0.36436709731890266, 0.1624304707873273), 5: (67006, 0.36948643768843875, 0.05809070354546968), 6: (760585, 0.34522435012695335, 0.6593874840481607), 7: (219243, 0.6481769847274379, 0.19007223408977417)}\n",
      "\n",
      "layer:18, initial_distribution of embeddings to experts:\n",
      " {0: (269057, 0.2150290330576562, 0.23325837124784998), 1: (543168, 0.21331653068803624, 0.4708982966209843), 2: (210631, 0.4751575499364542, 0.18260607973145426), 3: (96634, 0.581314827893169, 0.08377663263607613), 4: (91882, 0.5384097698088199, 0.07965689674305054), 5: (279375, 0.5058312775818824, 0.24220353853409532), 6: (749165, 0.3002284117080363, 0.6494869402985075), 7: (67032, 0.4917605984309135, 0.05811324418798202)}\n",
      "\n",
      "layer:19, initial_distribution of embeddings to experts:\n",
      " {0: (176852, 0.34780957059109807, 0.153321450368973), 1: (761181, 0.29462750243843944, 0.6599041849303667), 2: (80539, 0.5330076420963903, 0.06982310797314542), 3: (742899, 0.28933374915624943, 0.6440546454530323), 4: (79931, 0.610683901277663, 0.06929600371747212), 5: (243277, 0.5673651389188328, 0.21090845724907062), 6: (64500, 0.45994042987971345, 0.05591813238639516), 7: (157765, 0.434497630324518, 0.1367740179215447)}\n",
      "\n",
      "layer:20, initial_distribution of embeddings to experts:\n",
      " {0: (237485, 0.6925865035359553, 0.20588709565555124), 1: (120749, 0.26779056127130074, 0.10468307856627643), 2: (76318, 0.6151053952940851, 0.06616372135604505), 3: (136024, 0.45828419834391154, 0.11792570604227931), 4: (745792, 0.36023723284267045, 0.6465627254064251), 5: (364473, 0.2296436207024557, 0.3159790614770016), 6: (460551, 0.25430575568043756, 0.3992736711424291), 7: (165552, 0.3400020192092752, 0.14352494035399213)}\n",
      "\n",
      "layer:21, initial_distribution of embeddings to experts:\n",
      " {0: (173096, 0.2843192544877986, 0.15006519447372801), 1: (147966, 0.24127045079014148, 0.1282787965377573), 2: (81532, 0.6343082095538528, 0.07068398712755923), 3: (168823, 0.30627302144707136, 0.14636072657160296), 4: (79742, 0.6037832792664379, 0.06913215058536315), 5: (251689, 0.7129842429444135, 0.2182012220496033), 6: (642993, 0.23486147668870308, 0.5574413596515564), 7: (761103, 0.3122243453182754, 0.6598365630028297)}\n",
      "\n",
      "layer:22, initial_distribution of embeddings to experts:\n",
      " {0: (208632, 0.23418157683673493, 0.18087305110137047), 1: (75965, 0.6735577921835041, 0.06585768878655052), 2: (714645, 0.28566934812044675, 0.6195599026244244), 3: (762909, 0.4337428933331337, 0.6614022707096487), 4: (251551, 0.7101818619894477, 0.21808158325473007), 5: (94157, 0.4289464872065225, 0.08162920296288076), 6: (66590, 0.4142247545878474, 0.057730053265272155), 7: (132495, 0.3392266952432307, 0.1148662472951229)}\n",
      "\n",
      "layer:23, initial_distribution of embeddings to experts:\n",
      " {0: (245836, 0.3361951552137361, 0.21312697664095878), 1: (56149, 0.31658701995263716, 0.048678251400987624), 2: (250675, 0.6298841463619518, 0.2173221369916218), 3: (72485, 0.7107770273695653, 0.06284071048105198), 4: (183173, 0.27959458958510197, 0.1588014273428397), 5: (774582, 0.7938062848386619, 0.6715221522499029), 6: (658298, 0.10893301595272131, 0.5707099955612274), 7: (65746, 0.43187113547714606, 0.05699834933140987)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_expert_stats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3eae5ea-8873-4bfa-b126-d3cf7e26128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_all_expert_stats(model):\n",
    "    layers = get_layers(model)\n",
    "    for i, layer in enumerate(layers):    \n",
    "        experts = layer.mlp\n",
    "        experts.reset_expert_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38199010-0d02-42e5-a900-58ac9395169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_all_expert_stats(model):\n",
    "    layers = get_layers(model)\n",
    "    for i, layer in enumerate(layers):\n",
    "        experts = layer.mlp\n",
    "        experts.dump_expert_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eddafc18-8f44-422a-904f-974cc8634de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_all_expert_stats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d8e55-1f1d-4725-9d04-9c28ea702b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='1666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  88/1666 43:23 < 13:16:09, 0.03 it/s, Epoch 0.10/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebaa77-b4dd-450d-973b-dc4a47465fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(trainer.state, \"./tmp/trainer_state_20.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f83c1-0e39-447e-983b-cc82affca68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7747a96-c9d9-491d-9038-e5b94a804022",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c832d-9ecb-4807-8dee-e081a8c18753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_on_nlp_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea76f62a-c3fc-4e67-bb14-413d56422c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110433d8-8edb-4498-acfc-81b82fe885c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d79529-534e-403c-b3d2-0b02a9680940",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    eval_res = evaluate_on_nlp_tasks(model, tokenizer, limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b1de3-966c-46ae-b824-8dc7ab9ac4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf00bb-f362-488d-9631-dd15a723283f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_res = evaluate_on_nlp_tasks(model, tokenizer, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d57837-716d-4aed-b695-f39210ec33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592962c-bce7-41cc-b8af-1e5446f8a438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0764816e-9495-4911-a415-d91ed9e33cf5",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d3586-1954-40cb-8e05-7f501ef932cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d6a89-24aa-4872-83bc-a07d66f4be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./tmp/model_state_dict_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2612c-7683-4000-8cc8-0b8e378312f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a094e2-ade6-4b62-9727-ac6d81969a78",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361be45-fb3b-4655-b957-0a151f82460f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f079f0-584a-471f-a9e4-f8ac3aa9168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.layers[0].mlp.experts_fc1[0].lora_A.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be6781-0c8a-4650-b5d4-334e5f698053",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.layers[1].mlp.experts_fc1[0].lora_A.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634565c-bc4d-41dc-8650-9b20e5efef83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d90a3-be05-4f1a-8a6f-3a4474b31c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eaea87-d19c-4eda-980e-7ed9546ca1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83340de0-5185-471d-b7e2-40bfc8fe49a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb021c1-13a2-4925-8c1c-925deb8fb055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d25c98a-0b8a-44d5-843e-f519eb4d3c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d93e92-f096-4301-8811-5ef869c801a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1215ab07-7e15-48fa-a668-3afb2cb36418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
