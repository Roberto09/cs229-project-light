{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9d4ff2-4608-47d9-9497-a2d7502a3e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8f0249-bb0a-4d33-8e93-d54b3a727a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70d98c3-53fb-4065-b2cd-e383c2d7fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87fc2eb6-d0fe-4825-830e-0c7762f26723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from post_training import get_lora_config, get_training_arguments\n",
    "from dataset import get_baseline_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26a6f0f-b5f9-4d02-8f3b-50e6cd97f477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7a4d0693cf44cab893b4888b269f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tiny_textbooks = load_dataset(\"nampdn-ai/tiny-textbooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf5e531-79ae-49d2-90c0-b8b65d4c1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookcorpus = load_dataset(\"bookcorpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aaa38ac1-b184-4d8b-af3b-339fe227ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikitext = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2206fcc-b448-4aae-9ad1-b44f57691b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for c4 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/c4\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "c4 = load_dataset(\"c4\", \"en\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a9ff26-2945-4e08-bc2c-77ff1e59e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "minipile = load_dataset(\"JeanKaddour/minipile\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25feec16-e676-4f54-ac59-598fbe846ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = load_dataset(\"tatsu-lab/alpaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88cae0-e006-433f-b9e8-91caea171653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a411972a-fb91-4e41-b3b8-41e9c76dfcf3",
   "metadata": {},
   "source": [
    "## Dataset helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aed657c-4a7e-4bde-9f2b-11c74a2a9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, list_of_strings, tokenizer, max_length=2048):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.total_calls = 0\n",
    "        self.total_length = 0\n",
    "        tokenizer.padding_side = \"right\"\n",
    "        pad = \"do_not_pad\"\n",
    "        self.max_length = max_length\n",
    "        for s in list_of_strings:\n",
    "            encoded = tokenizer(\n",
    "                text=s + tokenizer.eos_token,\n",
    "                return_tensors=\"np\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=pad,\n",
    "            )\n",
    "            self.total_length += encoded['input_ids'].shape[1]\n",
    "            self.data.append({\n",
    "                'input_ids': encoded['input_ids'].squeeze(0),\n",
    "                'labels': encoded['input_ids'].squeeze(0),\n",
    "                'attention_mask': encoded['attention_mask'].squeeze(0)\n",
    "            })\n",
    "        self.mean_length = self.total_length / len(list_of_strings)\n",
    "        self.packed_data = self.data.copy()\n",
    "        #self.pack(64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.packed_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.packed_data[idx]\n",
    "\n",
    "class TokenizedQADataset(TokenizedDataset):\n",
    "    \"\"\"\n",
    "    Same as the tokenized dataset, but designed to \"mask out\" the labels of\n",
    "    the prompts such that they don't affect the model's loss.\n",
    "    \n",
    "    Question and answer pairs are concatenated as they are given. Make sure\n",
    "    to include the right separator between them (\" \", \"\\n\", \". \", etc.)\n",
    "    \"\"\"\n",
    "    def __init__(self, list_of_question_answers, tokenizer, max_length=2048):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.total_calls = 0\n",
    "        self.total_length = 0\n",
    "        tokenizer.padding_side = \"right\"\n",
    "        self.max_length = max_length\n",
    "        for question, answer in list_of_question_answers:\n",
    "            encoded_question = tokenizer(\n",
    "                text=question,\n",
    "                return_tensors=\"np\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"do_not_pad\",\n",
    "            )\n",
    "            encoded_answer = tokenizer(\n",
    "                text=answer+tokenizer.eos_token,\n",
    "                return_tensors=\"np\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "            )\n",
    "            encoded_inputs = np.concatenate([encoded_question[\"input_ids\"],\n",
    "                                            encoded_answer[\"input_ids\"]], axis=-1)\n",
    "            # labels have to be -100 so that the question does not affect the model's loss\n",
    "            encoded_labels = np.concatenate([np.array([-100] * encoded_question[\"input_ids\"].shape[-1])[None, :],\n",
    "                                            encoded_answer[\"input_ids\"]], axis=-1)\n",
    "            encoded_attention_mask = np.concatenate([encoded_question[\"attention_mask\"],\n",
    "                                            encoded_answer[\"attention_mask\"]], axis=-1)\n",
    "            encoded_labels[encoded_labels == tokenizer.eos_token_id] = -100\n",
    "\n",
    "            self.total_length += encoded_inputs.shape[1]\n",
    "            self.data.append({\n",
    "                'input_ids': encoded_inputs.squeeze(0)[:max_length],\n",
    "                'labels': encoded_labels.squeeze(0)[:max_length],\n",
    "                'attention_mask': encoded_attention_mask.squeeze(0)[:max_length]\n",
    "            })\n",
    "        self.mean_length = self.total_length / len(list_of_question_answers)\n",
    "        self.packed_data = self.data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cab2f42-0551-4cf2-947b-8fbee428bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpaca = TokenizedQADataset(alpaca_list_ds, tokenizer, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8936663e-f0f0-47b5-8b8c-9bdc25bd6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from trl import SFTTrainer\n",
    "\n",
    "# def fn(x, y, *args):\n",
    "#     return y\n",
    "\n",
    "# SFTTrainer._prepare_dataset = fn\n",
    "\n",
    "# from transformers import DataCollatorWithPadding\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=alpaca,\n",
    "#     eval_dataset=alpaca,\n",
    "#     # tokenizer=tokenizer,\n",
    "#     args=training_arguments,\n",
    "#     # packing=False,\n",
    "#     dataset_text_field=\"text\",\n",
    "#     max_seq_length=256, # tweak this,\n",
    "#     data_collator=DataCollatorWithPadding(tokenizer)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6299047-0d31-4b73-8207-eac84b7eec5a",
   "metadata": {},
   "source": [
    "## post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "260bf5e2-5705-4c93-88e6-80d47e23a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "def to_dataset(iterable_dataset):\n",
    "    data_list = [item for item in iterable_dataset]\n",
    "    dataset = Dataset.from_dict({key: [dic[key] for dic in data_list] for key in data_list[0]})\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00b4efef-48fc-4c35-9074-054b3066ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = c4[\"train\"].take(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fe24bfd-2934-4368-ab29-db2a2fa39a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "c4 = to_dataset(c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d83ffb9-825e-4bfe-a79e-76051172f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.',\n",
       " 'timestamp': '2019-04-25T12:57:54Z',\n",
       " 'url': 'https://klyq.com/beginners-bbq-class-taking-place-in-missoula/'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(c4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "605f06e8-b960-4b53-99e4-a66f58811c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "minipile = minipile[\"train\"].take(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b830953e-8ebe-405e-934b-eaec65cb76df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"HTC's Vive Pro headset is available to pre-order for $799\\n\\nWe've seen plenty of Beats-focused KIRFs in our time, some better than others. Few, however, play quite so directly on the name as OrigAudio's Beets. For $25, adopters get a set of headphones that bear little direct resemblance to Dr. Dre's audio gear of choice, but are no doubt bound to impress friends -- at least, up until they see a root vegetable logo instead of a lower-case B. Thankfully, there's more to it than just amusing and confusing peers. Every purchase will lead to a donation of canned beets (what else?) to the Second Harvest Food Bank of Orange County. For us, that's reason enough to hope that Beats doesn't put the kibosh on OrigAudio's effort. Besides, we could use some accompaniment for our BeetBox.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(minipile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc25caad-f813-4dc0-b8b2-96f695291c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "minipile = to_dataset(minipile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5ff59-7215-47d1-a154-58b785096c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ef03de-dcdd-4938-b132-77325deeb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_textbooks = tiny_textbooks[\"train\"].shuffle().select(range(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd3a847f-5a0a-4995-8a96-f0b69a9c9880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Manu Korihi News for 29 November 2011. One of the new Green Party MPs, who's Maori, says there's still a long way to go to have the Treaty of Waitangi recognised properly; A lawyer representing a whanau member, who took the body of James Takamore, says a series of meetings will be held with the wider hapu to talk about how to proceed following a court ruling; The senior Maori advisor at Massey University says this year's Nga Kupu Ora Maori Book Awards is a chance to celebrate a milestone in Maori language publishing; Waikato University's Te Piringa Faculty of Law, launched a new research centre today, which will tackle a variety of environmental law issues, including Maori and indigenous governance.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(tiny_textbooks))[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80e36a-55bf-46ac-b02a-061168543145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4a7fc47-5349-4866-938b-c1f45c0c51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookcorpus = bookcorpus[\"train\"].shuffle().select(range(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74778c1d-15df-4150-9f63-d4e28aa4b2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'outside , the storm continued to rage , beating against the windows , but inside they were locked in their own world .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(bookcorpus))[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cec86a-e635-4db5-9427-62def9de9193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32d3e1d4-713f-4a74-a4dd-1d0bf11b205a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8315bf417314339af92a7223466d1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wikitext = wikitext[\"train\"].filter(lambda example: len(example[\"text\"]) >= 200).shuffle().select(range(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45e0371e-3d81-4ba3-98c0-fdcd79010eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \" In the second stanza , the tree is a sucking babe drawing nourishment from Mother Earth ; in the third it is a supplicant reaching its leafy arms to the sky in prayer ... In the fourth stanza , the tree is a girl with jewels ( a nest of robins ) in her hair ; and in the fifth , it is a chaste woman living alone with nature and with God . There is no warrant in the poem to say that it is different trees that remind the poet of these different types of people . \" \\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikitext[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4103bd67-0bc9-40ec-aca8-0bb8d7958879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "072f9db3-0152-4238-b60b-b34e99485f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = alpaca[\"train\"].shuffle().select(range(0, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d134193-d7a4-4525-8602-8013509f415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_template = {\n",
    "    \"description\": \"Template used by Alpaca-LoRA.\",\n",
    "    \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n",
    "    \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n",
    "    \"response_split\": \"### Response:\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b0cb569-b9c5-4aec-8a40-f871ab6b6f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_list_ds = []\n",
    "for sample in alpaca.to_list():\n",
    "    if sample[\"input\"] != \"\":\n",
    "        prompt = alpaca_template[\"prompt_input\"].format(instruction=sample[\"instruction\"], input=sample[\"input\"])\n",
    "    else:\n",
    "        prompt = alpaca_template[\"prompt_no_input\"].format(instruction=sample[\"instruction\"])\n",
    "    response = sample[\"output\"]\n",
    "    alpaca_list_ds.append((prompt, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "abee2584-9d26-4c8f-9041-d1844c9001c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1d623a8-5567-4add-bd0d-aa27661a6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca = TokenizedQADataset(alpaca_list_ds, tokenizer, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c628777-079b-4a03-8f69-80bf0ce08606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "672e2c46-bc55-4592-9508-6cf2a1c375df",
   "metadata": {},
   "source": [
    "## Evaluating Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ad755-73a3-4f8e-9749-ef1f8dafe1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"microsoft/phi-1_5\"\n",
    "# model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acd694db-6b43-430b-a6c6-d781082f0253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50295"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95411b62-72fa-4292-a4a8-bd029d6a4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=model_revision,\n",
    "    trust_remote_code=True,\n",
    "    # be careful with this?\n",
    "    # torch_dtype=torch.float16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b9d1274-1cb4-48b0-9cf3-aad0a1ca5fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_arguments = get_training_arguments(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "042d8122-658e-4269-a768-ebb3d623dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1541701-c9a2-4808-8897-af09a0e27ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(dataset, custom_dataset=False):\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_arguments,\n",
    "        packing=False,\n",
    "        dataset_text_field=\"text\",\n",
    "        max_seq_length=256, # tweak this,\n",
    "        data_collator= DataCollatorWithPadding(tokenizer) if custom_dataset else None\n",
    "    )\n",
    "    return trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d825edb3-309d-4e50-b2c0-78f05bdeabfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd22672e282f42af8a6720a276e27c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c779c24d2d244de09d2c7d6f57b6ce25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce537273902a4031bfe67fad1a0ac497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4062ceebe694916be805f8a030a59ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdf8bdae8e94b66af89ff79b5b7d63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281eb842e4d04b2daf4aab8fefadd015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:43]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_res = {}\n",
    "for ds in [c4, minipile, tiny_textbooks, wikitext, alpaca]:\n",
    "    eval_res[ds] = evaluate_dataset(ds, custom_dataset=ds==alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1122c4f-f794-4bcd-89ea-20471312397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_res[alpaca] = evaluate_dataset(alpaca, custom_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88ef74a8-0b03-42a2-a7db-d3d2f399e1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'timestamp', 'url'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "{'eval_loss': 3.2249398231506348, 'eval_runtime': 53.4456, 'eval_samples_per_second': 37.421, 'eval_steps_per_second': 4.678}\n",
      "=============\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "{'eval_loss': 2.792614698410034, 'eval_runtime': 53.4744, 'eval_samples_per_second': 37.401, 'eval_steps_per_second': 4.675}\n",
      "=============\n",
      "Dataset({\n",
      "    features: ['text', 'source', 's', 'len', 'idx', 'textbook'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "{'eval_loss': 3.3270151615142822, 'eval_runtime': 52.5336, 'eval_samples_per_second': 38.071, 'eval_steps_per_second': 4.759}\n",
      "=============\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "{'eval_loss': 4.042848110198975, 'eval_runtime': 43.792, 'eval_samples_per_second': 45.67, 'eval_steps_per_second': 5.709}\n",
      "=============\n",
      "<__main__.TokenizedQADataset object at 0x7fb22d267b10>\n",
      "{'eval_loss': 1.5633244514465332, 'eval_runtime': 53.5137, 'eval_samples_per_second': 37.374, 'eval_steps_per_second': 4.672}\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "for ds, res in eval_res.items():\n",
    "    print(ds)\n",
    "    print(res)\n",
    "    print(\"=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "169338c5-b805-4e70-a701-ca80112640e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2c52ba7ec24ce6a01823f62e08e8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.7951738834381104,\n",
       " 'eval_runtime': 50.3011,\n",
       " 'eval_samples_per_second': 39.761,\n",
       " 'eval_steps_per_second': 4.97}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore the result from wikitext above, consider instead this one:\n",
    "evaluate_dataset(wikitext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef3581-8d54-4897-be8e-6f058738757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f40601-bf42-4d85-83c6-7b192b2df931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3876fa-35de-42e3-a00a-3a2c15888d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34c2d1-2cd8-42f0-a2de-f7e2b8261301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
