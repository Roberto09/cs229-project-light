{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12cc1aaf-5b39-4745-9d30-6eaed0b604b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71fb2b1c-405f-4aae-af0a-dcc938168c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a65062-72ba-40f0-ad0c-e37ed36df9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset_preprocessing import TokenInfo\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376ae97-4ec1-46d5-b640-566545c2e21d",
   "metadata": {},
   "source": [
    "## Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7943d9f-9fa3-4ae3-8e5b-2b8978c909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importances():\n",
    "    # print(\"this is wrong\")\n",
    "    dir = \"./new_importances_data\"\n",
    "    imp_files = os.listdir(dir)\n",
    "    imp_files = [file for file in imp_files if file.endswith(\".pkl\")]\n",
    "    importances = {}\n",
    "    for imp_file in tqdm(imp_files):\n",
    "        importances.update(pd.read_pickle(f\"{dir}/{imp_file}\"))\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b949f6-b4f0-420a-b379-bdcb27600d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imps = get_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6aee5d8-b934-4388-a280-226e823cfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_imporances(importances):\n",
    "    avg_imps = [torch.zeros_like(imp) for imp in list(importances.values())[0]]\n",
    "    for token, imps in tqdm(importances.items()):\n",
    "        for i, layer_imps in enumerate(imps):\n",
    "            avg_imps[i] += layer_imps / len(importances)\n",
    "    # TODO think harder about averaging method\n",
    "    return avg_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b49a204-d574-4c49-a615-f6cbe0d68103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_importances = get_avg_imporances(imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b9cea4-4361-4750-935a-c313302ba106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(avg_importances, \"./avg_importances.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7daa4f-5525-4bc6-ab49-df4e159f3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importances = pd.read_pickle(\"./avg_importances.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f94d76e-fa17-4f7d-b1f6-cdad75876469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4532c3-06f6-4353-b261-92acee331bbc",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b0cc63-e94b-4d1e-aff7-ea5c7310e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a84556f1-3c37-4283-bbdb-7d57b2f8d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434047b0-2814-4a7d-8b36-26bb8cea6ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50295"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0188674e-b98b-4880-8ea1-f5c7793d6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(token_info.get_prefixes(top_tokens[1000][0], 9, 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b379b1d8-0ab9-44df-83ed-089795112f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=model_revision,\n",
    "    trust_remote_code=True,\n",
    "    # be careful with this?\n",
    "    # torch_dtype=torch.float16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29bb579-da14-4e34-b37f-eba117b1e816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c698778-7f3b-4cf8-8bfe-6b0c54849ca2",
   "metadata": {},
   "source": [
    "## Prune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9250468a-c3e1-498a-8799-bbbbc763f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prunners import prune_mlps_holistically\n",
    "from importances import get_mlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11be390-99df-4b99-9e18-25255d3d269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps = get_mlps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "207a1fcd-edaf-43e2-a52d-ba4fc39b7c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlps), len(avg_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0810f24f-cb59-4c40-9b66-588c669bb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importances = dict(zip(mlps, avg_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c222ae1-5dcd-4801-96dc-0ebdfd10666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_mlps_holistically(avg_importances, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b96da5cc-9b2c-44e1-8b38-ef0592767ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=6633, bias=True)\n",
       "          (fc2): Linear(in_features=6633, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8120, bias=True)\n",
       "          (fc2): Linear(in_features=8120, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (2): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8189, bias=True)\n",
       "          (fc2): Linear(in_features=8189, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (3): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8128, bias=True)\n",
       "          (fc2): Linear(in_features=8128, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (4): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=7851, bias=True)\n",
       "          (fc2): Linear(in_features=7851, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (5): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=7511, bias=True)\n",
       "          (fc2): Linear(in_features=7511, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (6): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=6654, bias=True)\n",
       "          (fc2): Linear(in_features=6654, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (7): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=5839, bias=True)\n",
       "          (fc2): Linear(in_features=5839, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (8): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=4708, bias=True)\n",
       "          (fc2): Linear(in_features=4708, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (9): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=4189, bias=True)\n",
       "          (fc2): Linear(in_features=4189, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (10): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=3891, bias=True)\n",
       "          (fc2): Linear(in_features=3891, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (11): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=3579, bias=True)\n",
       "          (fc2): Linear(in_features=3579, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (12): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=3947, bias=True)\n",
       "          (fc2): Linear(in_features=3947, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (13): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=4243, bias=True)\n",
       "          (fc2): Linear(in_features=4243, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (14): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=5114, bias=True)\n",
       "          (fc2): Linear(in_features=5114, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (15): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=6032, bias=True)\n",
       "          (fc2): Linear(in_features=6032, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (16): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=7047, bias=True)\n",
       "          (fc2): Linear(in_features=7047, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (17): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=7545, bias=True)\n",
       "          (fc2): Linear(in_features=7545, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (18): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=7922, bias=True)\n",
       "          (fc2): Linear(in_features=7922, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (19): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8043, bias=True)\n",
       "          (fc2): Linear(in_features=8043, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (20): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8128, bias=True)\n",
       "          (fc2): Linear(in_features=8128, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (21): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8141, bias=True)\n",
       "          (fc2): Linear(in_features=8141, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (22): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=8114, bias=True)\n",
       "          (fc2): Linear(in_features=8114, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (23): PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=7719, bias=True)\n",
       "          (fc2): Linear(in_features=7719, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f326120-797c-4596-98c0-2741ccbc8338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028756c1-b952-49e2-acad-476c47285710",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3b61461-c77a-498c-b35c-c25e7188e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftConfig\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5f8ba3c-7105-4836-b44b-67ad39f908e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from post_training import get_lora_config, get_training_arguments\n",
    "from dataset import get_baseline_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2762576-56bf-4b88-8d9e-71388e4446a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = get_lora_config()\n",
    "training_arguments = get_training_arguments(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6b2d3d7-2622-4e18-a8e7-f3644f1a2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments.save_steps = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad26f2bb-f8ec-4c3b-9a2c-cfd92da7ecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc563e00-7011-41c3-b548-9bab5fdb3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6927d003-e04d-4399-a32a-a13dd04a61dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pickle\n"
     ]
    }
   ],
   "source": [
    "dataset = get_baseline_dataset()\n",
    "train_data, eval_data = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fafbd2f-2df9-422c-bf54-b4805c964c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1be350ca-6480-4f83-8dee-f553471febf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments.save_strategy=\"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e59a8478-4378-4fd3-b938-d6fe52fe4050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7442690f4a4e629f2fdf6b51f72830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd607a64f6cc4fc8b5a9b43b80522559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024, # tweak this\n",
    "    # TODO: think harder about the datacollator\n",
    "    # data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "    #     tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14603e19-b51b-4f71-965e-07d5f8cfe46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 30:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.494065761566162,\n",
       " 'eval_runtime': 169.1167,\n",
       " 'eval_samples_per_second': 11.826,\n",
       " 'eval_steps_per_second': 1.478}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c114811-973f-4b48-aa39-afb752d4b4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='901' max='1666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 901/1666 4:04:27 < 3:28:01, 0.06 it/s, Epoch 1.08/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.239200</td>\n",
       "      <td>3.195374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.156100</td>\n",
       "      <td>3.144388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.169300</td>\n",
       "      <td>3.128358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.086200</td>\n",
       "      <td>3.120554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.067600</td>\n",
       "      <td>3.115312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.142400</td>\n",
       "      <td>3.111253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.091500</td>\n",
       "      <td>3.108431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.158200</td>\n",
       "      <td>3.105942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [142/250 01:39 < 01:15, 1.42 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_res = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12ebaa77-b4dd-450d-973b-dc4a47465fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(trainer.state, \"./tmp/trainer_state_llm_pruner_style_0.2ratio_holistic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d21577ec-dd89-4189-ae61-c888258355a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>100</td>\n",
       "      <td>3.195374</td>\n",
       "      <td>170.2413</td>\n",
       "      <td>11.748</td>\n",
       "      <td>1.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>200</td>\n",
       "      <td>3.144388</td>\n",
       "      <td>170.1082</td>\n",
       "      <td>11.757</td>\n",
       "      <td>1.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>300</td>\n",
       "      <td>3.128358</td>\n",
       "      <td>170.1579</td>\n",
       "      <td>11.754</td>\n",
       "      <td>1.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48</td>\n",
       "      <td>400</td>\n",
       "      <td>3.120554</td>\n",
       "      <td>170.0755</td>\n",
       "      <td>11.759</td>\n",
       "      <td>1.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>500</td>\n",
       "      <td>3.115312</td>\n",
       "      <td>170.1386</td>\n",
       "      <td>11.755</td>\n",
       "      <td>1.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72</td>\n",
       "      <td>600</td>\n",
       "      <td>3.111253</td>\n",
       "      <td>170.0991</td>\n",
       "      <td>11.758</td>\n",
       "      <td>1.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>700</td>\n",
       "      <td>3.108431</td>\n",
       "      <td>170.1744</td>\n",
       "      <td>11.753</td>\n",
       "      <td>1.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>800</td>\n",
       "      <td>3.105942</td>\n",
       "      <td>170.1269</td>\n",
       "      <td>11.756</td>\n",
       "      <td>1.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.08</td>\n",
       "      <td>900</td>\n",
       "      <td>3.104341</td>\n",
       "      <td>170.0521</td>\n",
       "      <td>11.761</td>\n",
       "      <td>1.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.103140</td>\n",
       "      <td>170.0689</td>\n",
       "      <td>11.760</td>\n",
       "      <td>1.470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1100</td>\n",
       "      <td>3.101944</td>\n",
       "      <td>170.3087</td>\n",
       "      <td>11.743</td>\n",
       "      <td>1.468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1200</td>\n",
       "      <td>3.100909</td>\n",
       "      <td>168.8786</td>\n",
       "      <td>11.843</td>\n",
       "      <td>1.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1300</td>\n",
       "      <td>3.099982</td>\n",
       "      <td>168.8655</td>\n",
       "      <td>11.844</td>\n",
       "      <td>1.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1400</td>\n",
       "      <td>3.099221</td>\n",
       "      <td>168.8812</td>\n",
       "      <td>11.843</td>\n",
       "      <td>1.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1500</td>\n",
       "      <td>3.098641</td>\n",
       "      <td>168.8265</td>\n",
       "      <td>11.846</td>\n",
       "      <td>1.481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1600</td>\n",
       "      <td>3.098261</td>\n",
       "      <td>168.8576</td>\n",
       "      <td>11.844</td>\n",
       "      <td>1.481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  learning_rate  epoch  step  eval_loss  eval_runtime  \\\n",
       "11    NaN            NaN   0.12   100   3.195374      170.2413   \n",
       "22    NaN            NaN   0.24   200   3.144388      170.1082   \n",
       "33    NaN            NaN   0.36   300   3.128358      170.1579   \n",
       "44    NaN            NaN   0.48   400   3.120554      170.0755   \n",
       "55    NaN            NaN   0.60   500   3.115312      170.1386   \n",
       "66    NaN            NaN   0.72   600   3.111253      170.0991   \n",
       "77    NaN            NaN   0.84   700   3.108431      170.1744   \n",
       "88    NaN            NaN   0.96   800   3.105942      170.1269   \n",
       "99    NaN            NaN   1.08   900   3.104341      170.0521   \n",
       "110   NaN            NaN   1.20  1000   3.103140      170.0689   \n",
       "121   NaN            NaN   1.32  1100   3.101944      170.3087   \n",
       "132   NaN            NaN   1.44  1200   3.100909      168.8786   \n",
       "143   NaN            NaN   1.56  1300   3.099982      168.8655   \n",
       "154   NaN            NaN   1.68  1400   3.099221      168.8812   \n",
       "165   NaN            NaN   1.80  1500   3.098641      168.8265   \n",
       "176   NaN            NaN   1.92  1600   3.098261      168.8576   \n",
       "\n",
       "     eval_samples_per_second  eval_steps_per_second  train_runtime  \\\n",
       "11                    11.748                  1.469            NaN   \n",
       "22                    11.757                  1.470            NaN   \n",
       "33                    11.754                  1.469            NaN   \n",
       "44                    11.759                  1.470            NaN   \n",
       "55                    11.755                  1.469            NaN   \n",
       "66                    11.758                  1.470            NaN   \n",
       "77                    11.753                  1.469            NaN   \n",
       "88                    11.756                  1.469            NaN   \n",
       "99                    11.761                  1.470            NaN   \n",
       "110                   11.760                  1.470            NaN   \n",
       "121                   11.743                  1.468            NaN   \n",
       "132                   11.843                  1.480            NaN   \n",
       "143                   11.844                  1.480            NaN   \n",
       "154                   11.843                  1.480            NaN   \n",
       "165                   11.846                  1.481            NaN   \n",
       "176                   11.844                  1.481            NaN   \n",
       "\n",
       "     train_samples_per_second  train_steps_per_second  total_flos  train_loss  \n",
       "11                        NaN                     NaN         NaN         NaN  \n",
       "22                        NaN                     NaN         NaN         NaN  \n",
       "33                        NaN                     NaN         NaN         NaN  \n",
       "44                        NaN                     NaN         NaN         NaN  \n",
       "55                        NaN                     NaN         NaN         NaN  \n",
       "66                        NaN                     NaN         NaN         NaN  \n",
       "77                        NaN                     NaN         NaN         NaN  \n",
       "88                        NaN                     NaN         NaN         NaN  \n",
       "99                        NaN                     NaN         NaN         NaN  \n",
       "110                       NaN                     NaN         NaN         NaN  \n",
       "121                       NaN                     NaN         NaN         NaN  \n",
       "132                       NaN                     NaN         NaN         NaN  \n",
       "143                       NaN                     NaN         NaN         NaN  \n",
       "154                       NaN                     NaN         NaN         NaN  \n",
       "165                       NaN                     NaN         NaN         NaN  \n",
       "176                       NaN                     NaN         NaN         NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_state = trainer.state\n",
    "pd.DataFrame(trainer_state.log_history).dropna(subset = [\"eval_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7747a96-c9d9-491d-9038-e5b94a804022",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff2c832d-9ecb-4807-8dee-e081a8c18753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_on_nlp_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "110433d8-8edb-4498-acfc-81b82fe885c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2d79529-534e-403c-b3d2-0b02a9680940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02:01:56:05,153 WARNING  [huggingface.py:105] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-03-02:01:56:05,165 WARNING  [huggingface.py:315] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|| 3000/3000 [01:31<00:00, \n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    eval_res = evaluate_on_nlp_tasks(model, tokenizer, limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e73b1de3-966c-46ae-b824-8dc7ab9ac4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hellaswag': {'acc,none': 0.45,\n",
       "  'acc_norm,none': 0.5233333333333333,\n",
       "  'alias': 'hellaswag'},\n",
       " 'piqa': {'acc,none': 0.7333333333333333,\n",
       "  'acc_norm,none': 0.7366666666666667,\n",
       "  'alias': 'piqa'},\n",
       " 'boolq': {'acc,none': 0.6, 'alias': 'boolq'},\n",
       " 'winogrande': {'acc,none': 0.6733333333333333, 'alias': 'winogrande'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61cf00bb-f362-488d-9631-dd15a723283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|| 10000/10000 [05:04<00:00\n",
      "fatal: not a git repository (or any parent up to mount point /)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    }
   ],
   "source": [
    "eval_res = evaluate_on_nlp_tasks(model, tokenizer, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1d57837-716d-4aed-b695-f39210ec33f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hellaswag': {'acc,none': 0.428,\n",
       "  'acc_norm,none': 0.531,\n",
       "  'alias': 'hellaswag'},\n",
       " 'piqa': {'acc,none': 0.742, 'acc_norm,none': 0.737, 'alias': 'piqa'},\n",
       " 'boolq': {'acc,none': 0.622, 'alias': 'boolq'},\n",
       " 'winogrande': {'acc,none': 0.655, 'alias': 'winogrande'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c91c5-116f-46a3-ae4e-632b0fcf7f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c1b2289-ca6a-4d8d-96ff-57faf39ee348",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39060dc2-d38f-4033-ac62-512d56f30e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b0d8b9b-d226-491e-955b-1a6adaa50883",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./tmp/model_llm_prunner_style_0.2_ratio_holistic_state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e15bc-1a1a-4c63-8c3e-0f653a9f8fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
