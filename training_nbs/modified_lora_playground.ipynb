{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9081c6f-4853-42bd-a9b2-1dc53397e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfbdc3e4-e53c-4ff0-99d5-d9b726867305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c00ba53c-30b9-432b-82bf-4993220f136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset_preprocessing import TokenInfo\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb087f16-ebee-4e51-adc8-9327fc2ca0f3",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffc13e9-fbb6-4a07-898e-ef9efdec56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af56176e-cfc4-4962-a82b-a9b2aa7326aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4553a4-3ad1-43b6-9873-7ca703fcd630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50295"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b62611-f787-4b7c-b448-36e764e016aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(token_info.get_prefixes(top_tokens[1000][0], 9, 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b07137-ea7d-4c7d-bdcf-00451ff5755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=model_revision,\n",
    "    trust_remote_code=True,\n",
    "    # be careful with this?\n",
    "    # torch_dtype=torch.float16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761044bd-e992-4df7-a3da-4d465859fec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be645846-92b3-444d-8bb8-cf25224f0132",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ede8cb5-a71b-4277-b361-4715c9fb389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftConfig\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43e619b6-26df-43be-b248-dd699d8a97b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from post_training import get_lora_config, get_training_arguments\n",
    "from dataset import get_baseline_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd77bd3-d161-4992-bd35-e1de8de6f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = get_lora_config()\n",
    "training_arguments = get_training_arguments(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56079189-b905-458f-9195-0abf08125151",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments.save_steps = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6949d72-f1ca-4708-b3e8-b3cd1edce5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7ee18be-b822-45b6-a250-604f99219657",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "602457fa-b122-44ce-81dd-04fa25dd192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pickle\n"
     ]
    }
   ],
   "source": [
    "dataset = get_baseline_dataset()\n",
    "train_data, eval_data = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f691c21-789f-4d9f-b05c-a900a0f2cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0facbf48-9b99-4b06-8c96-fc96e05b1ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc3b52b881542adbb7f06b96f627380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8972908f3ae42c8ab75ef8f730edd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024, # tweak this\n",
    "    # TODO: think harder about the datacollator\n",
    "    # data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "    #     tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bc0a045e-6b9c-4cb1-9b0c-ffcec4d304af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class ModifiedLora(nn.Module):\n",
    "    def __init__(self, orig_lora, activation_fn, is_fc1):\n",
    "        super().__init__()\n",
    "        self.orig_lora = orig_lora\n",
    "        self.is_fc1 = is_fc1\n",
    "        self.activation_fn = activation_fn\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, *args, **kwargs) -> torch.Tensor:\n",
    "        # This is just copied from the original lora.Linear forward\n",
    "        previous_dtype = x.dtype\n",
    "        if self.orig_lora.disable_adapters:\n",
    "            assert False\n",
    "            if self.orig_lora.merged:\n",
    "                self.orig_lora.unmerge()\n",
    "            result = self.orig_lora.base_layer(x, *args, **kwargs)\n",
    "        elif self.orig_lora.merged:\n",
    "            assert False\n",
    "            result = self.orig_lora.base_layer(x, *args, **kwargs)\n",
    "        else:\n",
    "            assert len(self.orig_lora.active_adapters) == 1\n",
    "            active_adapter = next(iter(self.orig_lora.active_adapters))\n",
    "            if active_adapter not in self.orig_lora.lora_A.keys():\n",
    "                assert False\n",
    "            lora_A = self.orig_lora.lora_A[active_adapter]\n",
    "            lora_B = self.orig_lora.lora_B[active_adapter]\n",
    "            dropout = self.orig_lora.lora_dropout[active_adapter]\n",
    "            scaling = self.orig_lora.scaling[active_adapter]\n",
    "            h1 = self.orig_lora.base_layer(x, *args, **kwargs)\n",
    "            h2 = lora_B(lora_A(dropout(x))) * scaling\n",
    "            if self.is_fc1:\n",
    "                result = self.activation_fn(h1) + self.activation_fn(h2)\n",
    "            else:\n",
    "                result = self.activation_fn(h1 + h2)\n",
    "        result = result.to(previous_dtype)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bda511da-575a-4244-9ca4-92b7bcc91bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = model.model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a153e442-8b39-43fd-9d1a-b40830999f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_activ_fn = mlp.activation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b68953d-563a-482c-a9b5-ed081f143b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.activation_fn = torch.nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d94fc6f7-a69b-45d4-9d82-598d364dcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_linear_fc1 = ModifiedLora(mlp.fc1, orig_activ_fn, is_fc1=True)\n",
    "lora_linear_fc2 = ModifiedLora(mlp.fc2, orig_activ_fn, is_fc1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9a82e33-8a19-487f-9a9a-b7d4117cc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fc1 = lora_linear_fc1\n",
    "mlp.fc2 = lora_linear_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b80d42c-6ab9-4039-84fa-fdf73581233c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88953241-f00b-4827-86e3-718bf66deeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_lora_adapter(mlp):\n",
    "    orig_activ_fn = mlp.activation_fn\n",
    "    mlp.activation_fn = torch.nn.Identity()\n",
    "    lora_linear_fc1 = ModifiedLora(mlp.fc1, orig_activ_fn, is_fc1=True)\n",
    "    lora_linear_fc2 = ModifiedLora(mlp.fc2, orig_activ_fn, is_fc1=False)\n",
    "    mlp.fc1 = lora_linear_fc1\n",
    "    mlp.fc2 = lora_linear_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae83189-7557-4dfa-b47d-338c6f952ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_lora_adapters():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e411bfd1-7c38-426c-bf59-4a95e89d71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): lora.Linear(\n",
       "            (base_layer): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=8192, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (fc2): lora.Linear(\n",
       "            (base_layer): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=8192, out_features=8, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.activation_fn("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e828980-a4cb-48b1-9dea-fd232ec62024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f1d45-0d5e-46e0-a113-1cb25ccf44dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7682ef3-805a-4349-88f9-6dc38b4f771e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
