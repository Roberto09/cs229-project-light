{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12cc1aaf-5b39-4745-9d30-6eaed0b604b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230c69de-48c2-46e3-b034-c5b502e7bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557725f2-8a35-4fbb-97a0-4ec3bec89df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a65062-72ba-40f0-ad0c-e37ed36df9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset_preprocessing import TokenInfo\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d376ae97-4ec1-46d5-b640-566545c2e21d",
   "metadata": {},
   "source": [
    "## Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7943d9f-9fa3-4ae3-8e5b-2b8978c909a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importances():\n",
    "    # print(\"this is wrong\")\n",
    "    dir = \"./new_importances_data\"\n",
    "    imp_files = os.listdir(dir)\n",
    "    imp_files = [file for file in imp_files if file.endswith(\".pkl\")]\n",
    "    importances = {}\n",
    "    for imp_file in tqdm(imp_files):\n",
    "        importances.update(pd.read_pickle(f\"{dir}/{imp_file}\"))\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b949f6-b4f0-420a-b379-bdcb27600d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imps = get_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6aee5d8-b934-4388-a280-226e823cfc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_imporances(importances):\n",
    "    avg_imps = [torch.zeros_like(imp) for imp in list(importances.values())[0]]\n",
    "    for token, imps in tqdm(importances.items()):\n",
    "        for i, layer_imps in enumerate(imps):\n",
    "            avg_imps[i] += layer_imps / len(importances)\n",
    "    # TODO think harder about averaging method\n",
    "    return avg_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b49a204-d574-4c49-a615-f6cbe0d68103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_importances = get_avg_imporances(imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b9cea4-4361-4750-935a-c313302ba106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(avg_importances, \"./avg_importances.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e94f831b-94e5-4ea1-99a9-348521b132c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_dataset.pkl  cs229-project  pcs224n  tmp-cs229-project\n",
      "cs229\t\t      LLM-Pruner     tmp\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7daa4f-5525-4bc6-ab49-df4e159f3449",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importances = pd.read_pickle(\"./avg_importances.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f94d76e-fa17-4f7d-b1f6-cdad75876469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4532c3-06f6-4353-b261-92acee331bbc",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b0cc63-e94b-4d1e-aff7-ea5c7310e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"microsoft/phi-1_5\"\n",
    "model_revision = \"349cf8b5e81fd5f791d1740da5de1313a0419bbd\" # latest as of feb 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a84556f1-3c37-4283-bbdb-7d57b2f8d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434047b0-2814-4a7d-8b36-26bb8cea6ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0188674e-b98b-4880-8ea1-f5c7793d6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.decode(token_info.get_prefixes(top_tokens[1000][0], 9, 10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b379b1d8-0ab9-44df-83ed-089795112f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    revision=model_revision,\n",
    "    trust_remote_code=True,\n",
    "    # be careful with this?\n",
    "    # torch_dtype=torch.float16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29bb579-da14-4e34-b37f-eba117b1e816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c698778-7f3b-4cf8-8bfe-6b0c54849ca2",
   "metadata": {},
   "source": [
    "## Prune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9250468a-c3e1-498a-8799-bbbbc763f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prunners import prune_mlps_individually\n",
    "from importances import get_mlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11be390-99df-4b99-9e18-25255d3d269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlps = get_mlps(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207a1fcd-edaf-43e2-a52d-ba4fc39b7c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlps), len(avg_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0810f24f-cb59-4c40-9b66-588c669bb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importances = dict(zip(mlps, avg_importances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c222ae1-5dcd-4801-96dc-0ebdfd10666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_mlps_individually(avg_importances, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b96da5cc-9b2c-44e1-8b38-ef0592767ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): Embedding(51200, 2048)\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): PhiMLP(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (fc1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b2b6f-45a6-4329-bdd3-171d70d2038f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028756c1-b952-49e2-acad-476c47285710",
   "metadata": {},
   "source": [
    "## Replace model modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "129af7bc-6a05-4d98-b0e5-ebe9ea37159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from experts import Experts, EmbeddingTokenIdxTracker, mark_only_adapters_as_trainable, prepare_as_if_peft_model, prepare_model_for_gradient_checkpointing\n",
    "from importances import get_mlps\n",
    "from post_training import get_lora_config, get_training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1694358-33a6-4323-be62-fb5c6660b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = get_lora_config()\n",
    "training_arguments = get_training_arguments(\"./tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b3db38f-f332-4fb9-8cbe-da4578d71d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = prepare_as_if_peft_model(model, training_arguments, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389136c-d30f-486e-aa89-42d47ded3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c60286a8-da58-451c-ba60-5539e6f37588",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_tokens_new = EmbeddingTokenIdxTracker(model.get_submodule(\"model\").get_submodule(\"embed_tokens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c3be121-252c-4076-85f4-1149821f4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(model):\n",
    "    return model.get_submodule(\"model\").get_submodule(\"layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2371bb5-6bd5-4832-94de-07e58a7997f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = get_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc6cab4a-a81d-415d-850c-544bab24d128",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_submodule(\"model\").embed_tokens = embed_tokens_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a9f488d-2ea2-4e47-bafe-cee9856f4c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(layers):\n",
    "    layer.mlp = Experts(\n",
    "        model,\n",
    "        layer.mlp,\n",
    "        lora_config,\n",
    "        i,\n",
    "        embed_tokens_new.idx_tracker,\n",
    "        layer.mlp.config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82509117-64fd-410c-86bc-6a9145151c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_only_adapters_as_trainable(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44f81670-8720-40f8-871e-88c97cd630e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): EmbeddingTokenIdxTracker(\n",
       "      (embed): Embedding(51200, 2048)\n",
       "    )\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Experts(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (cluster_router): ClusterRouter()\n",
       "          (experts_fc1): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "          (experts_fc2): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_model_for_gradient_checkpointing(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d5aa50-ccb0-402f-b8b9-9a30a51ec311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8482f4a-8430-4d3e-aa9d-8f7b0def7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\"hi this is an example\", \"hi this is an example\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3067f38a-ffb5-471c-8ff5-7f1770837f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = torch.tensor(tokenizer.encode(examples)).view(-1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84c33521-8b1a-41cc-8ebc-30189ce05c45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiForCausalLM(\n",
       "  (model): PhiModel(\n",
       "    (embed_tokens): EmbeddingTokenIdxTracker(\n",
       "      (embed): Embedding(51200, 2048)\n",
       "    )\n",
       "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x PhiDecoderLayer(\n",
       "        (self_attn): PhiAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (rotary_emb): PhiRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Experts(\n",
       "          (activation_fn): NewGELUActivation()\n",
       "          (cluster_router): ClusterRouter()\n",
       "          (experts_fc1): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "          (experts_fc2): ModuleList(\n",
       "            (0-7): 8 x lora.Linear(\n",
       "              (base_layer): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.05, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "043ab127-fe1b-495f-847e-d5e84a621f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = model(examples.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0229563-96d2-4bbe-a23b-8df5c92c822d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3eb57e0-ca3f-49ed-b43b-a5874dc6d583",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5fa8dd8-6987-4888-8583-592da2e56506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_training import get_lora_config, get_training_arguments\n",
    "from dataset import get_baseline_dataset\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "import transformers\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "318fb266-d940-4daa-b643-07247fbc9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading pickle\n"
     ]
    }
   ],
   "source": [
    "dataset = get_baseline_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98807c9d-ad41-48c1-82c1-6beffcace426",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments.save_strategy=\"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ef8bc33-998c-4c3c-a979-e05d0d6938dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab14f2509e974f1982eb9d01dd2bc73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c333bfff1946718ea79aa180b688ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Setup model for training\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Setup tokenizer for trainign\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "train_data, eval_data = dataset[\"train\"], dataset[\"test\"]\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    # peft_config=lora_config,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024, # tweak this\n",
    "    # TODO: think harder about the datacollator\n",
    "    # data_collator=transformers.DataCollatorForSeq2Seq(\n",
    "    #     tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91f25bee-d634-4262-b712-27b4d6384d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 41:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.6767449378967285,\n",
       " 'eval_runtime': 177.2892,\n",
       " 'eval_samples_per_second': 11.281,\n",
       " 'eval_steps_per_second': 1.41}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c0d8e55-1f1d-4725-9d04-9c28ea702b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1501' max='1666' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1501/1666 10:42:27 < 1:10:43, 0.04 it/s, Epoch 1.80/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.719400</td>\n",
       "      <td>3.650269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.508400</td>\n",
       "      <td>3.491539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.497600</td>\n",
       "      <td>3.446306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.394700</td>\n",
       "      <td>3.422544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.357500</td>\n",
       "      <td>3.407472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.435700</td>\n",
       "      <td>3.397186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.378300</td>\n",
       "      <td>3.389771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.438100</td>\n",
       "      <td>3.383795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.345300</td>\n",
       "      <td>3.380591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.337700</td>\n",
       "      <td>3.378289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.366100</td>\n",
       "      <td>3.375446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.324500</td>\n",
       "      <td>3.373434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.404800</td>\n",
       "      <td>3.371444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.369200</td>\n",
       "      <td>3.369768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [163/250 01:55 < 01:01, 1.41 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b71a4a0a-e89d-4528-8736-f062c6a39652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>100</td>\n",
       "      <td>3.650269</td>\n",
       "      <td>240.8597</td>\n",
       "      <td>8.304</td>\n",
       "      <td>1.038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>200</td>\n",
       "      <td>3.491539</td>\n",
       "      <td>243.8529</td>\n",
       "      <td>8.202</td>\n",
       "      <td>1.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "      <td>300</td>\n",
       "      <td>3.446306</td>\n",
       "      <td>242.4336</td>\n",
       "      <td>8.250</td>\n",
       "      <td>1.031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.48</td>\n",
       "      <td>400</td>\n",
       "      <td>3.422544</td>\n",
       "      <td>242.5270</td>\n",
       "      <td>8.247</td>\n",
       "      <td>1.031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>500</td>\n",
       "      <td>3.407472</td>\n",
       "      <td>242.0004</td>\n",
       "      <td>8.264</td>\n",
       "      <td>1.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72</td>\n",
       "      <td>600</td>\n",
       "      <td>3.397186</td>\n",
       "      <td>241.7342</td>\n",
       "      <td>8.274</td>\n",
       "      <td>1.034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>700</td>\n",
       "      <td>3.389771</td>\n",
       "      <td>241.4236</td>\n",
       "      <td>8.284</td>\n",
       "      <td>1.036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>800</td>\n",
       "      <td>3.383795</td>\n",
       "      <td>241.3092</td>\n",
       "      <td>8.288</td>\n",
       "      <td>1.036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.08</td>\n",
       "      <td>900</td>\n",
       "      <td>3.380591</td>\n",
       "      <td>241.6424</td>\n",
       "      <td>8.277</td>\n",
       "      <td>1.035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1000</td>\n",
       "      <td>3.378289</td>\n",
       "      <td>240.9427</td>\n",
       "      <td>8.301</td>\n",
       "      <td>1.038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1100</td>\n",
       "      <td>3.375446</td>\n",
       "      <td>252.5788</td>\n",
       "      <td>7.918</td>\n",
       "      <td>0.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1200</td>\n",
       "      <td>3.373434</td>\n",
       "      <td>176.1425</td>\n",
       "      <td>11.354</td>\n",
       "      <td>1.419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1300</td>\n",
       "      <td>3.371444</td>\n",
       "      <td>176.0776</td>\n",
       "      <td>11.359</td>\n",
       "      <td>1.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1400</td>\n",
       "      <td>3.369768</td>\n",
       "      <td>176.1027</td>\n",
       "      <td>11.357</td>\n",
       "      <td>1.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1500</td>\n",
       "      <td>3.368622</td>\n",
       "      <td>175.7908</td>\n",
       "      <td>11.377</td>\n",
       "      <td>1.422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1600</td>\n",
       "      <td>3.367812</td>\n",
       "      <td>176.2112</td>\n",
       "      <td>11.350</td>\n",
       "      <td>1.419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  learning_rate  epoch  step  eval_loss  eval_runtime  \\\n",
       "11    NaN            NaN   0.12   100   3.650269      240.8597   \n",
       "22    NaN            NaN   0.24   200   3.491539      243.8529   \n",
       "33    NaN            NaN   0.36   300   3.446306      242.4336   \n",
       "44    NaN            NaN   0.48   400   3.422544      242.5270   \n",
       "55    NaN            NaN   0.60   500   3.407472      242.0004   \n",
       "66    NaN            NaN   0.72   600   3.397186      241.7342   \n",
       "77    NaN            NaN   0.84   700   3.389771      241.4236   \n",
       "88    NaN            NaN   0.96   800   3.383795      241.3092   \n",
       "99    NaN            NaN   1.08   900   3.380591      241.6424   \n",
       "110   NaN            NaN   1.20  1000   3.378289      240.9427   \n",
       "121   NaN            NaN   1.32  1100   3.375446      252.5788   \n",
       "132   NaN            NaN   1.44  1200   3.373434      176.1425   \n",
       "143   NaN            NaN   1.56  1300   3.371444      176.0776   \n",
       "154   NaN            NaN   1.68  1400   3.369768      176.1027   \n",
       "165   NaN            NaN   1.80  1500   3.368622      175.7908   \n",
       "176   NaN            NaN   1.92  1600   3.367812      176.2112   \n",
       "\n",
       "     eval_samples_per_second  eval_steps_per_second  train_runtime  \\\n",
       "11                     8.304                  1.038            NaN   \n",
       "22                     8.202                  1.025            NaN   \n",
       "33                     8.250                  1.031            NaN   \n",
       "44                     8.247                  1.031            NaN   \n",
       "55                     8.264                  1.033            NaN   \n",
       "66                     8.274                  1.034            NaN   \n",
       "77                     8.284                  1.036            NaN   \n",
       "88                     8.288                  1.036            NaN   \n",
       "99                     8.277                  1.035            NaN   \n",
       "110                    8.301                  1.038            NaN   \n",
       "121                    7.918                  0.990            NaN   \n",
       "132                   11.354                  1.419            NaN   \n",
       "143                   11.359                  1.420            NaN   \n",
       "154                   11.357                  1.420            NaN   \n",
       "165                   11.377                  1.422            NaN   \n",
       "176                   11.350                  1.419            NaN   \n",
       "\n",
       "     train_samples_per_second  train_steps_per_second  total_flos  train_loss  \n",
       "11                        NaN                     NaN         NaN         NaN  \n",
       "22                        NaN                     NaN         NaN         NaN  \n",
       "33                        NaN                     NaN         NaN         NaN  \n",
       "44                        NaN                     NaN         NaN         NaN  \n",
       "55                        NaN                     NaN         NaN         NaN  \n",
       "66                        NaN                     NaN         NaN         NaN  \n",
       "77                        NaN                     NaN         NaN         NaN  \n",
       "88                        NaN                     NaN         NaN         NaN  \n",
       "99                        NaN                     NaN         NaN         NaN  \n",
       "110                       NaN                     NaN         NaN         NaN  \n",
       "121                       NaN                     NaN         NaN         NaN  \n",
       "132                       NaN                     NaN         NaN         NaN  \n",
       "143                       NaN                     NaN         NaN         NaN  \n",
       "154                       NaN                     NaN         NaN         NaN  \n",
       "165                       NaN                     NaN         NaN         NaN  \n",
       "176                       NaN                     NaN         NaN         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_state = trainer.state\n",
    "pd.DataFrame(trainer_state.log_history).dropna(subset = [\"eval_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12ebaa77-b4dd-450d-973b-dc4a47465fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.to_pickle(trainer.state, \"./tmp/trainer_state_0.5ratio.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0facb-6dfe-4fac-93eb-459ed6da5494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7747a96-c9d9-491d-9038-e5b94a804022",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff2c832d-9ecb-4807-8dee-e081a8c18753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_on_nlp_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea76f62a-c3fc-4e67-bb14-413d56422c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "110433d8-8edb-4498-acfc-81b82fe885c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2d79529-534e-403c-b3d2-0b02a9680940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01:07:46:21,299 WARNING  [huggingface.py:105] `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.\n",
      "2024-03-01:07:46:21,343 WARNING  [huggingface.py:315] Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration\n",
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|▉| 2996/3000 [19:48<00:0IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    eval_res = evaluate_on_nlp_tasks(model, tokenizer, limit=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e73b1de3-966c-46ae-b824-8dc7ab9ac4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hellaswag': {'acc,none': 0.38,\n",
       "  'acc_norm,none': 0.4666666666666667,\n",
       "  'alias': 'hellaswag'},\n",
       " 'piqa': {'acc,none': 0.7133333333333334,\n",
       "  'acc_norm,none': 0.6966666666666667,\n",
       "  'alias': 'piqa'},\n",
       " 'boolq': {'acc,none': 0.6466666666666666, 'alias': 'boolq'},\n",
       " 'winogrande': {'acc,none': 0.58, 'alias': 'winogrande'}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61cf00bb-f362-488d-9631-dd15a723283f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/research/robgarct/.conda/envs/cs224n-pip3/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      " 30%|▎| 2998/10000 [20:20<45:IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_res = evaluate_on_nlp_tasks(model, tokenizer, limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1d57837-716d-4aed-b695-f39210ec33f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hellaswag': {'acc,none': 0.377,\n",
       "  'acc_norm,none': 0.489,\n",
       "  'alias': 'hellaswag'},\n",
       " 'piqa': {'acc,none': 0.717, 'acc_norm,none': 0.7, 'alias': 'piqa'},\n",
       " 'boolq': {'acc,none': 0.646, 'alias': 'boolq'},\n",
       " 'winogrande': {'acc,none': 0.588, 'alias': 'winogrande'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592962c-bce7-41cc-b8af-1e5446f8a438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaf33605-e246-4afb-a14a-886a15e964d2",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b94d3586-1954-40cb-8e05-7f501ef932cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b11d6a89-24aa-4872-83bc-a07d66f4be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./tmp/model_state_dict_0.5ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29104fb2-ba63-45be-9871-042c4a7ac79b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
